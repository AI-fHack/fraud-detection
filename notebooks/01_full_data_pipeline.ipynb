{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9110aeae-b07b-42f1-a6d0-59c558c23479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- –ó–ê–î–ê–ß–ê 1: –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–µ—Ä–≤–∏—á–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ (–î–µ–Ω—å 1) ---\n",
      "‚úÖ –¢–∞–±–ª–∏—Ü—ã –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã –∏ –æ—á–∏—â–µ–Ω—ã. –†–∞–∑–º–µ—Ä: (13155, 21). –£–¥–∞–ª–µ–Ω–æ —Å—Ç—Ä–æ–∫ (–∏–∑-–∑–∞ NaT): 0\n",
      "\n",
      "--- –ó–ê–î–ê–ß–ê 23: –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ ---\n",
      "‚úÖ –°–æ–∑–¥–∞–Ω–æ 13 –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: hour, day_of_week, day_of_month, month, is_weekend, is_night, –∏ —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è\n",
      "\n",
      "--- –ó–ê–î–ê–ß–ê 24: –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é ---\n",
      "‚úÖ –°–æ–∑–¥–∞–Ω–æ 8 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é: tx_count, avg/std/max/min amount, –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ\n",
      "\n",
      "--- –ó–ê–î–ê–ß–ê 25: –°–æ–∑–¥–∞–Ω–∏–µ rolling-window –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ---\n",
      "‚úÖ –°–æ–∑–¥–∞–Ω–æ 15 rolling-window –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–∫–æ–Ω ['1h', '12h', '24h']\n",
      "\n",
      "--- –ó–ê–î–ê–ß–ê 26: –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ---\n",
      "‚úÖ –°–æ–∑–¥–∞–Ω–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: z-scores, –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª–∏, –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –≤–∞—Ä–∏–∞—Ü–∏–∏\n",
      "\n",
      "--- –ó–ê–î–ê–ß–ê 27: –°–æ–∑–¥–∞–Ω–∏–µ device-based & geo-based –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ---\n",
      "–ù–∞–π–¥–µ–Ω–æ –∫–æ–ª–æ–Ω–æ–∫: —É—Å—Ç—Ä–æ–π—Å—Ç–≤=2, OS=5, IP=0, –≥–µ–æ–ª–æ–∫–∞—Ü–∏—è=0\n",
      "‚úÖ –°–æ–∑–¥–∞–Ω–æ 3 device-based –ø—Ä–∏–∑–Ω–∞–∫–∞ –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Ä–∞–∑–Ω—ã—Ö_–º–æ–¥–µ–ª–µ–π_—Ç–µ–ª–µ—Ñ–æ–Ω–∞__phone_model__–∑–∞_–ø–æ—Å–ª–µ–¥–Ω–∏–µ_30_–¥–Ω–µ–π___–Ω–∞—Å–∫–æ–ª—å–∫–æ_—á–∞—Å—Ç–æ_–∫–ª–∏–µ–Ω—Ç__–º–µ–Ω—è–ª_—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ__–ø–æ_–ª–æ–≥–∞–º\n",
      "‚úÖ –°–æ–∑–¥–∞–Ω–æ 2 OS-based –ø—Ä–∏–∑–Ω–∞–∫–∞ –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ_—Ä–∞–∑–Ω—ã—Ö_–≤–µ—Ä—Å–∏–π_–æ—Å__os_ver__–∑–∞_–ø–æ—Å–ª–µ–¥–Ω–∏–µ_30_–¥–Ω–µ–π_–¥–æ_transdate___—Å–∫–æ–ª—å–∫–æ_—Ä–∞–∑–Ω—ã—Ö_–æ—Å_–≤–µ—Ä—Å–∏–π_–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª_–∫–ª–∏–µ–Ω—Ç\n",
      "‚ö†Ô∏è IP –∞–¥—Ä–µ—Å–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –¥–∞–Ω–Ω—ã—Ö\n",
      "‚ö†Ô∏è –ì–µ–æ–ª–æ–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –¥–∞–Ω–Ω—ã—Ö\n",
      "\n",
      "--- –ó–ê–î–ê–ß–ê 28: –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ–≤–µ–¥–µ–Ω–∏—è (—Å–∫–æ—Ä–æ—Å—Ç—å –æ–ø–µ—Ä–∞—Ü–∏–π) ---\n",
      "‚úÖ –°–æ–∑–¥–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ–≤–µ–¥–µ–Ω–∏—è: –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã, —Å–∫–æ—Ä–æ—Å—Ç—å —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π, –∞–Ω–æ–º–∞–ª–∏–∏ —Å–∫–æ—Ä–æ—Å—Ç–∏\n",
      "\n",
      "--- –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: Frequency Encoding –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ---\n",
      "‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ö–æ–ª–æ–Ω–∫–∞ '–ü–æ–ª—É—á–∞—Ç–µ–ª—å' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∞ recipient_freq_encoding –ø—Ä–æ–ø—É—â–µ–Ω–æ.\n",
      "\n",
      "--- –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ---\n",
      "–ù–∞–π–¥–µ–Ω–æ 50 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è\n",
      "‚úÖ –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–æ 50 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.\n",
      "\n",
      "--- –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±–æ–≥–∞—â–µ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ ---\n",
      "\n",
      "‚úÖ –§–ò–ù–ê–õ–¨–ù–´–ô –û–ë–û–ì–ê–©–ï–ù–ù–´–ô –î–ê–¢–ê–°–ï–¢ –ì–û–¢–û–í: ../data/processed/transactions_with_features.csv\n",
      "–§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ç–∞–±–ª–∏—Ü—ã —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏: (13155, 85)\n",
      "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–±–µ–∑ target): 84\n",
      "\n",
      "üìä –°–í–û–î–ö–ê –ü–û –°–û–ó–î–ê–ù–ù–´–ú –ü–†–ò–ó–ù–ê–ö–ê–ú:\n",
      "  - –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: ~13 (—á–∞—Å, –¥–µ–Ω—å, —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è)\n",
      "  - –ü—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é: ~8 (—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é)\n",
      "  - Rolling-window –ø—Ä–∏–∑–Ω–∞–∫–∏: ~15 (–¥–ª—è –æ–∫–æ–Ω ['1h', '12h', '24h'])\n",
      "  - –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: ~13\n",
      "  - Device/OS/IP/Geo –ø—Ä–∏–∑–Ω–∞–∫–∏: –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –Ω–∞–ª–∏—á–∏—è –¥–∞–Ω–Ω—ã—Ö\n",
      "  - –ü—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ–≤–µ–¥–µ–Ω–∏—è: ~10+ (—Å–∫–æ—Ä–æ—Å—Ç—å, –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã, –∞–Ω–æ–º–∞–ª–∏–∏)\n",
      "\n",
      "‚úÖ –í—Å–µ –∑–∞–¥–∞—á–∏ Feature Engineering (23-28) –≤—ã–ø–æ–ª–Ω–µ–Ω—ã!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# --- –ö–û–ù–°–¢–ê–ù–¢–´ –ò –ü–ê–†–ê–ú–ï–¢–†–´ ---\n",
    "TRANS_FILE = '../data/—Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –≤ –ú–æ–±–∏–ª—å–Ω–æ–º –∏–Ω—Ç–µ—Ä–Ω–µ—Ç –ë–∞–Ω–∫–∏–Ω–≥–µ.csv'\n",
    "BEHAV_FILE = '../data/–ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∫–ª–∏–µ–Ω—Ç–æ–≤.csv'\n",
    "ENCODING = 'cp1251'\n",
    "DELIMITER = ';'\n",
    "DATE_FORMAT_SHORT = '%Y-%m-%d' \n",
    "\n",
    "FINAL_FEATURES_PATH = '../data/processed/transactions_with_features.csv'\n",
    "GROUPING_KEY = 'user_id'\n",
    "TIME_WINDOWS = ['1h', '12h', '24h']\n",
    "\n",
    "print(\"--- –ó–ê–î–ê–ß–ê 1: –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–µ—Ä–≤–∏—á–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ (–î–µ–Ω—å 1) ---\")\n",
    "\n",
    "# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "try:\n",
    "    df_trans = pd.read_csv(TRANS_FILE, encoding=ENCODING, sep=DELIMITER, header=1) \n",
    "    df_behav = pd.read_csv(BEHAV_FILE, encoding=ENCODING, sep=DELIMITER)\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –§–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!\")\n",
    "    raise\n",
    "\n",
    "# 2. –û—á–∏—Å—Ç–∫–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏–º–µ–Ω –∫–æ–ª–æ–Ω–æ–∫\n",
    "def clean_cols(df):\n",
    "    df.columns = df.columns.astype(str).str.replace(' ', '_').str.lower().str.replace('\"', '').str.strip()\n",
    "    df.columns = df.columns.str.replace(r'[^\\w]+', '_', regex=True).str.strip('_')\n",
    "    return df\n",
    "\n",
    "df_trans = clean_cols(df_trans)\n",
    "df_behav = clean_cols(df_behav)\n",
    "\n",
    "# 3. –û—á–∏—Å—Ç–∫–∞ –∫–æ–ª–æ–Ω–∫–∏ —Å—É–º–º—ã (amount)\n",
    "df_trans = df_trans[df_trans['target'].astype(str) != 'nan'].copy() \n",
    "df_trans['amount'] = df_trans['amount'].astype(str).str.replace(r'[\\.,]', '', regex=True).astype(float)\n",
    "\n",
    "\n",
    "# 4. –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –¥–∞—Ç –∏ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ\n",
    "df_trans['timestamp'] = pd.to_datetime(df_trans['transdatetime'], errors='coerce')\n",
    "\n",
    "df_behav.rename(columns={'–¥–∞—Ç–∞_—Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ–π_—Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏': 'date_behav'}, inplace=True)\n",
    "df_trans.rename(columns={'transdate': 'date_trans'}, inplace=True) \n",
    "\n",
    "df_behav['date_behav'] = pd.to_datetime(df_behav['date_behav'], format=DATE_FORMAT_SHORT, errors='coerce')\n",
    "df_trans['date_trans'] = pd.to_datetime(df_trans['date_trans'], format=DATE_FORMAT_SHORT, errors='coerce')\n",
    "\n",
    "# 5. –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ ID –∫–ª–∏–µ–Ω—Ç–∞\n",
    "df_behav.rename(columns={'—É–Ω–∏–∫–∞–ª—å–Ω—ã–π_–∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä_–∫–ª–∏–µ–Ω—Ç–∞': 'user_id'}, inplace=True)\n",
    "df_trans.rename(columns={'cst_dim_id': 'user_id'}, inplace=True)\n",
    "\n",
    "\n",
    "# –§–∏–∫—Å: –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ user_id –∫ —Å—Ç—Ä–æ–∫–æ–≤–æ–º—É —Ç–∏–ø—É\n",
    "df_trans['user_id'] = df_trans['user_id'].astype(str)\n",
    "df_behav['user_id'] = df_behav['user_id'].astype(str)\n",
    "\n",
    "\n",
    "# --- –ó–ê–î–ê–ß–ê 2: –°–ª–∏—è–Ω–∏–µ –∏ —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ (–î–µ–Ω—å 1-2) ---\n",
    "\n",
    "df_merged = pd.merge(\n",
    "    df_trans, \n",
    "    df_behav, \n",
    "    left_on=['user_id', 'date_trans'], \n",
    "    right_on=['user_id', 'date_behav'], \n",
    "    how='left',\n",
    "    suffixes=('_trans', '_behav')\n",
    ")\n",
    "\n",
    "initial_rows = df_merged.shape[0]\n",
    "df = df_merged[df_merged['timestamp'].notna()].copy()\n",
    "rows_dropped = initial_rows - df.shape[0]\n",
    "\n",
    "if df.shape[0] == 0:\n",
    "    print(f\"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ü–æ—Ç–µ—Ä—è–Ω—ã –í–°–ï {initial_rows} —Å—Ç—Ä–æ–∫ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö.\")\n",
    "    raise ValueError(\"DataFrame –ø—É—Å—Ç –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫.\")\n",
    "\n",
    "df.sort_values(by='timestamp', inplace=True)\n",
    "df.drop(columns=['date_trans', 'transdatetime', 'date_behav', 'docno', 'direction'], inplace=True, errors='ignore')\n",
    "\n",
    "df.fillna(0, inplace=True) \n",
    "\n",
    "print(f\"‚úÖ –¢–∞–±–ª–∏—Ü—ã –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã –∏ –æ—á–∏—â–µ–Ω—ã. –†–∞–∑–º–µ—Ä: {df.shape}. –£–¥–∞–ª–µ–Ω–æ —Å—Ç—Ä–æ–∫ (–∏–∑-–∑–∞ NaT): {rows_dropped}\")\n",
    "\n",
    "\n",
    "# --- –ó–ê–î–ê–ß–ê 23: –°–æ–∑–¥–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ ---\n",
    "print(\"\\n--- –ó–ê–î–ê–ß–ê 23: –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ ---\")\n",
    "\n",
    "# –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ timestamp\n",
    "# –≠—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ–º–æ–≥–∞—é—Ç –º–æ–¥–µ–ª–∏ –ø–æ–Ω—è—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞\n",
    "df['hour'] = df['timestamp'].dt.hour  # –ß–∞—Å –¥–Ω—è (0-23)\n",
    "df['day_of_week'] = df['timestamp'].dt.dayofweek  # –î–µ–Ω—å –Ω–µ–¥–µ–ª–∏ (0=–ü–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫, 6=–í–æ—Å–∫—Ä–µ—Å–µ–Ω—å–µ)\n",
    "df['day_of_month'] = df['timestamp'].dt.day  # –î–µ–Ω—å –º–µ—Å—è—Ü–∞ (1-31)\n",
    "df['month'] = df['timestamp'].dt.month  # –ú–µ—Å—è—Ü (1-12)\n",
    "df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)  # –í—ã—Ö–æ–¥–Ω–æ–π –¥–µ–Ω—å (1) –∏–ª–∏ —Ä–∞–±–æ—á–∏–π (0)\n",
    "df['is_night'] = ((df['hour'] >= 22) | (df['hour'] < 6)).astype(int)  # –ù–æ—á—å (22:00-06:00)\n",
    "\n",
    "# –¶–∏–∫–ª–∏—á–µ—Å–∫–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —á–∞—Å–∞ –∏ –¥–Ω—è –Ω–µ–¥–µ–ª–∏ (sin/cos) - –ø–æ–º–æ–≥–∞–µ—Ç –º–æ–¥–µ–ª–∏ –ø–æ–Ω—è—Ç—å —Ü–∏–∫–ª–∏—á–Ω–æ—Å—Ç—å\n",
    "df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "df['day_of_week_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
    "df['day_of_week_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "\n",
    "print(f\"‚úÖ –°–æ–∑–¥–∞–Ω–æ 13 –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: hour, day_of_week, day_of_month, month, is_weekend, is_night, –∏ —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è\")\n",
    "\n",
    "\n",
    "# --- –ó–ê–î–ê–ß–ê 24: –°–æ–∑–¥–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é (avg_amount, count) ---\n",
    "print(\"\\n--- –ó–ê–î–ê–ß–ê 24: –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é ---\")\n",
    "\n",
    "# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é (–≤—ã—á–∏—Å–ª—è—é—Ç—Å—è –ø–æ –≤—Å–µ–º –µ–≥–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è–º –¥–æ —Ç–µ–∫—É—â–µ–π)\n",
    "# –≠—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ–º–æ–≥–∞—é—Ç –ø–æ–Ω—è—Ç—å —Ç–∏–ø–∏—á–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "\n",
    "# –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π\n",
    "df_sorted = df.sort_values(by=['user_id', 'timestamp']).copy()\n",
    "\n",
    "# –ü—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é (–∏—Å–ø–æ–ª—å–∑—É–µ–º expanding window –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏)\n",
    "df_sorted['user_tx_count_total'] = df_sorted.groupby(GROUPING_KEY).cumcount() + 1  # –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–æ —Ç–µ–∫—É—â–µ–π\n",
    "df_sorted['user_avg_amount_total'] = df_sorted.groupby(GROUPING_KEY)['amount'].expanding().mean().reset_index(level=0, drop=True)\n",
    "df_sorted['user_std_amount_total'] = df_sorted.groupby(GROUPING_KEY)['amount'].expanding().std().reset_index(level=0, drop=True)\n",
    "df_sorted['user_max_amount_total'] = df_sorted.groupby(GROUPING_KEY)['amount'].expanding().max().reset_index(level=0, drop=True)\n",
    "df_sorted['user_min_amount_total'] = df_sorted.groupby(GROUPING_KEY)['amount'].expanding().min().reset_index(level=0, drop=True)\n",
    "\n",
    "# –û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "df_sorted['amount_diff_from_user_avg'] = df_sorted['amount'] - df_sorted['user_avg_amount_total']\n",
    "df_sorted['amount_ratio_to_user_avg'] = df_sorted['amount'] / (df_sorted['user_avg_amount_total'] + 1e-8)  # +1e-8 —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥–µ–ª–µ–Ω–∏—è –Ω–∞ 0\n",
    "\n",
    "# –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏ –¥–ª—è –ø–µ—Ä–≤–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –∫–∞–∂–¥–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "df_sorted['user_std_amount_total'].fillna(0, inplace=True)\n",
    "df_sorted['amount_diff_from_user_avg'].fillna(0, inplace=True)\n",
    "df_sorted['amount_ratio_to_user_avg'].fillna(1, inplace=True)\n",
    "\n",
    "# –û–±–Ω–æ–≤–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –¥–∞—Ç–∞—Ñ—Ä–µ–π–º\n",
    "df = df_sorted.copy()\n",
    "\n",
    "print(f\"‚úÖ –°–æ–∑–¥–∞–Ω–æ 8 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é: tx_count, avg/std/max/min amount, –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ\")\n",
    "\n",
    "\n",
    "# --- –ó–ê–î–ê–ß–ê 25: –°–æ–∑–¥–∞—Ç—å rolling-window –ø—Ä–∏–∑–Ω–∞–∫–∏ ---\n",
    "print(\"\\n--- –ó–ê–î–ê–ß–ê 25: –°–æ–∑–¥–∞–Ω–∏–µ rolling-window –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ---\")\n",
    "\n",
    "# Rolling Window Features - —Å–∫–æ–ª—å–∑—è—â–∏–µ –æ–∫–Ω–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏\n",
    "# –≠—Ç–∏ –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —á–∞—Å–æ–≤\n",
    "for window in TIME_WINDOWS:\n",
    "    # üî• –§–ò–ù–ê–õ–¨–ù–´–ô –§–ò–ö–°: –ò—Å–ø–æ–ª—å–∑—É–µ–º 'amount' –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π, —Ç–∞–∫ –∫–∞–∫ 'user_id' –º–æ–∂–µ—Ç –±—ã—Ç—å –∏—Å–∫–ª—é—á–µ–Ω –∏–∑ –≥—Ä—É–ø–ø—ã.\n",
    "    df[f'tx_count_{window}'] = df.groupby(GROUPING_KEY).apply(\n",
    "        lambda x: x.rolling(window=window, on='timestamp', closed='left')['amount'].count(),\n",
    "        include_groups=False \n",
    "    ).reset_index(level=0, drop=True)\n",
    "    \n",
    "    df[f'tx_mean_amount_{window}'] = df.groupby(GROUPING_KEY).apply(\n",
    "        lambda x: x.rolling(window=window, on='timestamp', closed='left')['amount'].mean(),\n",
    "        include_groups=False \n",
    "    ).reset_index(level=0, drop=True)\n",
    "    \n",
    "    df[f'tx_std_amount_{window}'] = df.groupby(GROUPING_KEY).apply(\n",
    "        lambda x: x.rolling(window=window, on='timestamp', closed='left')['amount'].std(),\n",
    "        include_groups=False \n",
    "    ).reset_index(level=0, drop=True)\n",
    "    \n",
    "    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ rolling –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "    df[f'tx_sum_amount_{window}'] = df.groupby(GROUPING_KEY).apply(\n",
    "        lambda x: x.rolling(window=window, on='timestamp', closed='left')['amount'].sum(),\n",
    "        include_groups=False \n",
    "    ).reset_index(level=0, drop=True)\n",
    "    \n",
    "    df[f'tx_max_amount_{window}'] = df.groupby(GROUPING_KEY).apply(\n",
    "        lambda x: x.rolling(window=window, on='timestamp', closed='left')['amount'].max(),\n",
    "        include_groups=False \n",
    "    ).reset_index(level=0, drop=True)\n",
    "\n",
    "print(f\"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(TIME_WINDOWS) * 5} rolling-window –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–∫–æ–Ω {TIME_WINDOWS}\")\n",
    "\n",
    "\n",
    "# --- –ó–ê–î–ê–ß–ê 26: –°–æ–∑–¥–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ---\n",
    "print(\"\\n--- –ó–ê–î–ê–ß–ê 26: –°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ---\")\n",
    "\n",
    "# Z-score –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –æ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ –≤ –µ–¥–∏–Ω–∏—Ü–∞—Ö —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è)\n",
    "# Z-score –ø–æ–º–æ–≥–∞–µ—Ç –≤—ã—è–≤–∏—Ç—å –∞–Ω–æ–º–∞–ª–∏–∏\n",
    "\n",
    "# Z-score –¥–ª—è amount –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è\n",
    "global_amount_mean = df['amount'].mean()\n",
    "global_amount_std = df['amount'].std() + 1e-8\n",
    "df['amount_zscore'] = (df['amount'] - global_amount_mean) / global_amount_std\n",
    "\n",
    "# Z-score –¥–ª—è amount –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–∏—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ –≤—ã—á–∏—Å–ª–µ–Ω–Ω—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏)\n",
    "df['amount_zscore_user'] = df['amount_diff_from_user_avg'] / (df['user_std_amount_total'] + 1e-8)\n",
    "\n",
    "# –ü—Ä–æ—Ü–µ–Ω—Ç–∏–ª–∏ amount\n",
    "df['amount_percentile'] = df['amount'].rank(pct=True)\n",
    "\n",
    "# –û—Ç–Ω–æ—à–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–π —Å—É–º–º—ã –∫ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π/–º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π –≤ –æ–∫–Ω–µ\n",
    "for window in TIME_WINDOWS:\n",
    "    mean_col = f'tx_mean_amount_{window}'\n",
    "    max_col = f'tx_max_amount_{window}'\n",
    "    if mean_col in df.columns and max_col in df.columns:\n",
    "        df[f'amount_ratio_to_max_{window}'] = df['amount'] / (df[max_col] + 1e-8)\n",
    "        df[f'amount_ratio_to_mean_{window}'] = df['amount'] / (df[mean_col] + 1e-8)\n",
    "\n",
    "# –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏ (std/mean) –¥–ª—è rolling –æ–∫–æ–Ω\n",
    "for window in TIME_WINDOWS:\n",
    "    mean_col = f'tx_mean_amount_{window}'\n",
    "    std_col = f'tx_std_amount_{window}'\n",
    "    if mean_col in df.columns and std_col in df.columns:\n",
    "        df[f'cv_amount_{window}'] = df[std_col] / (df[mean_col] + 1e-8)  # Coefficient of Variation\n",
    "\n",
    "print(f\"‚úÖ –°–æ–∑–¥–∞–Ω–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: z-scores, –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª–∏, –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –≤–∞—Ä–∏–∞—Ü–∏–∏\")\n",
    "\n",
    "\n",
    "# --- –ó–ê–î–ê–ß–ê 27: –°–æ–∑–¥–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ device-based & geo-based ---\n",
    "print(\"\\n--- –ó–ê–î–ê–ß–ê 27: –°–æ–∑–¥–∞–Ω–∏–µ device-based & geo-based –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ---\")\n",
    "\n",
    "# –ü–æ–∏—Å–∫ –∫–æ–ª–æ–Ω–æ–∫, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞–º–∏\n",
    "device_cols = []\n",
    "for col in df.columns:\n",
    "    col_lower = col.lower()\n",
    "    if 'phone' in col_lower or 'model' in col_lower or 'device' in col_lower or '—Ç–µ–ª–µ—Ñ–æ–Ω' in col_lower or '—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ' in col_lower:\n",
    "        device_cols.append(col)\n",
    "\n",
    "os_cols = []\n",
    "for col in df.columns:\n",
    "    col_lower = col.lower()\n",
    "    if 'os' in col_lower or '–≤–µ—Ä—Å–∏—è' in col_lower:\n",
    "        os_cols.append(col)\n",
    "\n",
    "# –ü–æ–∏—Å–∫ –∫–æ–ª–æ–Ω–æ–∫ —Å IP/–≥–µ–æ–ª–æ–∫–∞—Ü–∏–µ–π\n",
    "ip_cols = []\n",
    "geo_cols = []\n",
    "for col in df.columns:\n",
    "    col_lower = col.lower()\n",
    "    if 'ip' in col_lower or '–∞–¥—Ä–µ—Å' in col_lower:\n",
    "        ip_cols.append(col)\n",
    "    if 'geo' in col_lower or 'location' in col_lower or '—Å—Ç—Ä–∞–Ω–∞' in col_lower or '–≥–æ—Ä–æ–¥' in col_lower:\n",
    "        geo_cols.append(col)\n",
    "\n",
    "print(f\"–ù–∞–π–¥–µ–Ω–æ –∫–æ–ª–æ–Ω–æ–∫: —É—Å—Ç—Ä–æ–π—Å—Ç–≤={len(device_cols)}, OS={len(os_cols)}, IP={len(ip_cols)}, –≥–µ–æ–ª–æ–∫–∞—Ü–∏—è={len(geo_cols)}\")\n",
    "\n",
    "# Device-based –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "if len(device_cols) > 0:\n",
    "    device_col = device_cols[0]\n",
    "    # –ß–∞—Å—Ç–æ—Ç–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ (frequency encoding)\n",
    "    device_counts = df[device_col].value_counts()\n",
    "    df['device_freq'] = df[device_col].map(device_counts) / len(df)\n",
    "    \n",
    "    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤ –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "    df['user_unique_devices'] = df.groupby(GROUPING_KEY)[device_col].transform('nunique')\n",
    "    \n",
    "    # –ò–∑–º–µ–Ω–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ (1 –µ—Å–ª–∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏)\n",
    "    df['device_changed'] = (df.groupby(GROUPING_KEY)[device_col].shift(1) != df[device_col]).astype(int)\n",
    "    df['device_changed'].fillna(0, inplace=True)\n",
    "    \n",
    "    print(f\"‚úÖ –°–æ–∑–¥–∞–Ω–æ 3 device-based –ø—Ä–∏–∑–Ω–∞–∫–∞ –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ {device_col}\")\n",
    "\n",
    "# OS-based –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "if len(os_cols) > 0:\n",
    "    os_col = os_cols[0]\n",
    "    # –ß–∞—Å—Ç–æ—Ç–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è OS –≤–µ—Ä—Å–∏–∏\n",
    "    os_counts = df[os_col].value_counts()\n",
    "    df['os_freq'] = df[os_col].map(os_counts) / len(df)\n",
    "    \n",
    "    # –ò–∑–º–µ–Ω–µ–Ω–∏–µ OS –≤–µ—Ä—Å–∏–∏\n",
    "    df['os_changed'] = (df.groupby(GROUPING_KEY)[os_col].shift(1) != df[os_col]).astype(int)\n",
    "    df['os_changed'].fillna(0, inplace=True)\n",
    "    \n",
    "    print(f\"‚úÖ –°–æ–∑–¥–∞–Ω–æ 2 OS-based –ø—Ä–∏–∑–Ω–∞–∫–∞ –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ {os_col}\")\n",
    "\n",
    "# IP-based –ø—Ä–∏–∑–Ω–∞–∫–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)\n",
    "if len(ip_cols) > 0:\n",
    "    ip_col = ip_cols[0]\n",
    "    # –ß–∞—Å—Ç–æ—Ç–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è IP\n",
    "    ip_counts = df[ip_col].value_counts()\n",
    "    df['ip_freq'] = df[ip_col].map(ip_counts) / len(df)\n",
    "    \n",
    "    # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö IP –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è\n",
    "    df['user_unique_ips'] = df.groupby(GROUPING_KEY)[ip_col].transform('nunique')\n",
    "    \n",
    "    # –ò–∑–º–µ–Ω–µ–Ω–∏–µ IP –∞–¥—Ä–µ—Å–∞\n",
    "    df['ip_changed'] = (df.groupby(GROUPING_KEY)[ip_col].shift(1) != df[ip_col]).astype(int)\n",
    "    df['ip_changed'].fillna(0, inplace=True)\n",
    "    \n",
    "    print(f\"‚úÖ –°–æ–∑–¥–∞–Ω–æ 3 IP-based –ø—Ä–∏–∑–Ω–∞–∫–∞ –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ {ip_col}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è IP –∞–¥—Ä–µ—Å–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –¥–∞–Ω–Ω—ã—Ö\")\n",
    "\n",
    "# Geo-based –ø—Ä–∏–∑–Ω–∞–∫–∏ (–µ—Å–ª–∏ –µ—Å—Ç—å)\n",
    "if len(geo_cols) > 0:\n",
    "    geo_col = geo_cols[0]\n",
    "    # –ß–∞—Å—Ç–æ—Ç–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ª–æ–∫–∞—Ü–∏–∏\n",
    "    geo_counts = df[geo_col].value_counts()\n",
    "    df['geo_freq'] = df[geo_col].map(geo_counts) / len(df)\n",
    "    \n",
    "    # –ò–∑–º–µ–Ω–µ–Ω–∏–µ –ª–æ–∫–∞—Ü–∏–∏\n",
    "    df['geo_changed'] = (df.groupby(GROUPING_KEY)[geo_col].shift(1) != df[geo_col]).astype(int)\n",
    "    df['geo_changed'].fillna(0, inplace=True)\n",
    "    \n",
    "    print(f\"‚úÖ –°–æ–∑–¥–∞–Ω–æ 2 geo-based –ø—Ä–∏–∑–Ω–∞–∫–∞ –∏–∑ –∫–æ–ª–æ–Ω–∫–∏ {geo_col}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è –ì–µ–æ–ª–æ–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –¥–∞–Ω–Ω—ã—Ö\")\n",
    "\n",
    "\n",
    "# --- –ó–ê–î–ê–ß–ê 28: –°–æ–∑–¥–∞—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ–≤–µ–¥–µ–Ω–∏—è (—Å–∫–æ—Ä–æ—Å—Ç—å –æ–ø–µ—Ä–∞—Ü–∏–π) ---\n",
    "print(\"\\n--- –ó–ê–î–ê–ß–ê 28: –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ–≤–µ–¥–µ–Ω–∏—è (—Å–∫–æ—Ä–æ—Å—Ç—å –æ–ø–µ—Ä–∞—Ü–∏–π) ---\")\n",
    "\n",
    "# Lag Feature (time_since_last_tx) - —É–∂–µ –±—ã–ª–æ, –Ω–æ –¥–æ–±–∞–≤–∏–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ\n",
    "df['time_since_last_tx'] = df.groupby(GROUPING_KEY)['timestamp'].diff().dt.total_seconds()\n",
    "df['time_since_last_tx'].fillna(0, inplace=True)\n",
    "\n",
    "# –í—Ä–µ–º—è –¥–æ —Å–ª–µ–¥—É—é—â–µ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ (forward-looking, –Ω–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤)\n",
    "df['time_until_next_tx'] = df.groupby(GROUPING_KEY)['timestamp'].diff(-1).dt.total_seconds() * -1\n",
    "df['time_until_next_tx'].fillna(0, inplace=True)\n",
    "\n",
    "# –°–∫–æ—Ä–æ—Å—Ç—å —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –≤ —á–∞—Å)\n",
    "for window in TIME_WINDOWS:\n",
    "    count_col = f'tx_count_{window}'\n",
    "    if count_col in df.columns:\n",
    "        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –æ–∫–Ω–æ –≤ —á–∞—Å—ã –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Å–∫–æ—Ä–æ—Å—Ç–∏\n",
    "        hours_map = {'1h': 1, '12h': 12, '24h': 24}\n",
    "        hours = hours_map.get(window, 1)\n",
    "        df[f'tx_rate_per_hour_{window}'] = df[count_col] / hours\n",
    "\n",
    "# –°—Ä–µ–¥–Ω–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (rolling)\n",
    "for window in TIME_WINDOWS:\n",
    "    hours_map = {'1h': 1, '12h': 12, '24h': 24}\n",
    "    hours = hours_map.get(window, 1)\n",
    "    # –°—Ä–µ–¥–Ω–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª = –æ–∫–Ω–æ / –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π\n",
    "    count_col = f'tx_count_{window}'\n",
    "    if count_col in df.columns:\n",
    "        df[f'avg_interval_{window}'] = (hours * 3600) / (df[count_col] + 1)  # –≤ —Å–µ–∫—É–Ω–¥–∞—Ö\n",
    "\n",
    "# –ê–Ω–æ–º–∞–ª–∏–∏ –≤ —Å–∫–æ—Ä–æ—Å—Ç–∏ (—Å–ª–∏—à–∫–æ–º –±—ã—Å—Ç—Ä–æ –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –º–µ–¥–ª–µ–Ω–Ω–æ)\n",
    "# –ï—Å–ª–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª –º–µ–∂–¥—É —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è–º–∏ –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–π - –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ\n",
    "df['is_rapid_tx'] = (df['time_since_last_tx'] < 60).astype(int)  # –ú–µ–Ω—å—à–µ –º–∏–Ω—É—Ç—ã –º–µ–∂–¥—É —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è–º–∏\n",
    "\n",
    "# –ï—Å–ª–∏ –∏–Ω—Ç–µ—Ä–≤–∞–ª –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–π - —Ç–æ–∂–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ (–Ω–µ–æ–±—ã—á–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ)\n",
    "user_avg_interval = df.groupby(GROUPING_KEY)['time_since_last_tx'].transform('mean')\n",
    "df['interval_anomaly'] = (df['time_since_last_tx'] > user_avg_interval * 3).astype(int)  # –í 3 —Ä–∞–∑–∞ –±–æ–ª—å—à–µ —Å—Ä–µ–¥–Ω–µ–≥–æ\n",
    "\n",
    "# –ß–∞—Å—Ç–æ—Ç–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –≤ —Ä–∞–∑–Ω—ã–µ –ø–µ—Ä–∏–æ–¥—ã –¥–Ω—è\n",
    "df['tx_in_morning'] = ((df['hour'] >= 6) & (df['hour'] < 12)).astype(int)\n",
    "df['tx_in_afternoon'] = ((df['hour'] >= 12) & (df['hour'] < 18)).astype(int)\n",
    "df['tx_in_evening'] = ((df['hour'] >= 18) & (df['hour'] < 22)).astype(int)\n",
    "\n",
    "print(f\"‚úÖ –°–æ–∑–¥–∞–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–æ–≤–µ–¥–µ–Ω–∏—è: –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã, —Å–∫–æ—Ä–æ—Å—Ç—å —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π, –∞–Ω–æ–º–∞–ª–∏–∏ —Å–∫–æ—Ä–æ—Å—Ç–∏\")\n",
    "\n",
    "\n",
    "# --- –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: Frequency Encoding –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ---\n",
    "print(\"\\n--- –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ: Frequency Encoding –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ---\")\n",
    "\n",
    "# 3. Frequency Encoding –¥–ª—è 'recipient_id' (–µ—Å–ª–∏ –µ—Å—Ç—å)\n",
    "try:\n",
    "    recipient_col = [col for col in df.columns if '–ø–æ–ª—É—á–∞—Ç–µ–ª—è' in col or 'recipient' in col.lower()][0]\n",
    "    df[recipient_col].fillna('UNKNOWN_RECIPIENT', inplace=True)\n",
    "    recipient_counts = df[recipient_col].value_counts()\n",
    "    df['recipient_freq_encoding'] = df[recipient_col].map(recipient_counts) / len(df)\n",
    "    df.drop(columns=[recipient_col], inplace=True, errors='ignore')\n",
    "    print(f\"‚úÖ –°–æ–∑–¥–∞–Ω frequency encoding –¥–ª—è {recipient_col}\")\n",
    "except (IndexError, KeyError):\n",
    "    print(\"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ö–æ–ª–æ–Ω–∫–∞ '–ü–æ–ª—É—á–∞—Ç–µ–ª—å' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∞ recipient_freq_encoding –ø—Ä–æ–ø—É—â–µ–Ω–æ.\")\n",
    "    df['recipient_freq_encoding'] = 0\n",
    "\n",
    "\n",
    "# --- –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ---\n",
    "print(\"\\n--- –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ---\")\n",
    "\n",
    "# –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–∫—Ä–æ–º–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏—Ö –∏ –±–∏–Ω–∞—Ä–Ω—ã—Ö)\n",
    "cols_to_match = [\n",
    "    'amount', 'time_since_last_tx', 'time_until_next_tx', 'recipient_freq_encoding',\n",
    "    'user_avg_amount_total', 'user_std_amount_total', 'user_max_amount_total', 'user_min_amount_total',\n",
    "    'amount_zscore', 'amount_zscore_user', 'amount_percentile',\n",
    "    'device_freq', 'os_freq', 'ip_freq', 'geo_freq',\n",
    "    'tx_rate_per_hour', 'avg_interval'\n",
    "]\n",
    "\n",
    "# –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "features_to_scale = []\n",
    "for col in df.columns:\n",
    "    # –ò—Å–∫–ª—é—á–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (sin/cos), –±–∏–Ω–∞—Ä–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –∏ target\n",
    "    if any(match in col.lower() for match in ['_sin', '_cos', 'is_', 'changed', 'target', 'user_id', 'timestamp']):\n",
    "        continue\n",
    "    # –í–∫–ª—é—á–∞–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "    if df[col].dtype in [np.int64, np.int32, np.float64, np.float32]:\n",
    "        if col not in ['hour', 'day_of_week', 'day_of_month', 'month']:  # –ò—Å—Ö–æ–¥–Ω—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–µ –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º\n",
    "            features_to_scale.append(col)\n",
    "\n",
    "# –î–æ–±–∞–≤–ª—è–µ–º rolling window –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "for window in TIME_WINDOWS:\n",
    "    for suffix in ['count', 'mean', 'std', 'sum', 'max']:\n",
    "        col = f'tx_{suffix}_amount_{window}'\n",
    "        if col in df.columns:\n",
    "            features_to_scale.append(col)\n",
    "    for suffix in ['rate_per_hour', 'avg_interval']:\n",
    "        col = f'tx_{suffix}_{window}'\n",
    "        if col in df.columns:\n",
    "            features_to_scale.append(col)\n",
    "\n",
    "# –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "stat_cols = [col for col in df.columns if any(x in col for x in ['zscore', 'percentile', 'ratio', 'cv_amount'])]\n",
    "features_to_scale.extend(stat_cols)\n",
    "\n",
    "# –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ\n",
    "features_to_scale = list(set([col for col in features_to_scale if col in df.columns]))\n",
    "\n",
    "# –ò—Å–∫–ª—é—á–∞–µ–º target –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å\n",
    "if 'target' in features_to_scale:\n",
    "    features_to_scale.remove('target')\n",
    "\n",
    "print(f\"–ù–∞–π–¥–µ–Ω–æ {len(features_to_scale)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è\")\n",
    "\n",
    "if len(features_to_scale) > 0:\n",
    "    scaler = MinMaxScaler()\n",
    "    df_features = df[features_to_scale].copy()\n",
    "    df[features_to_scale] = scaler.fit_transform(df_features)\n",
    "    print(f\"‚úÖ –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–æ {len(features_to_scale)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è –ü—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã\")\n",
    "\n",
    "\n",
    "# --- –§–ò–ù–ê–õ–¨–ù–û–ï –°–û–•–†–ê–ù–ï–ù–ò–ï ---\n",
    "print(\"\\n--- –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±–æ–≥–∞—â–µ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ ---\")\n",
    "\n",
    "# –ó–∞–ø–æ–ª–Ω—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –ø—Ä–æ–ø—É—Å–∫–∏\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –Ω—É–∂–Ω—ã –¥–ª—è –º–æ–¥–µ–ª–∏ (–æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–∏–∑–Ω–∞–∫–∏)\n",
    "cols_to_drop = ['timestamp']  # timestamp –±–æ–ª—å—à–µ –Ω–µ –Ω—É–∂–µ–Ω, –≤—Å–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑–≤–ª–µ—á–µ–Ω—ã\n",
    "df.drop(columns=cols_to_drop, inplace=True, errors='ignore')\n",
    "\n",
    "output_dir = os.path.dirname(FINAL_FEATURES_PATH)\n",
    "if output_dir and not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "df.to_csv(FINAL_FEATURES_PATH, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ –§–ò–ù–ê–õ–¨–ù–´–ô –û–ë–û–ì–ê–©–ï–ù–ù–´–ô –î–ê–¢–ê–°–ï–¢ –ì–û–¢–û–í: {FINAL_FEATURES_PATH}\")\n",
    "print(f\"–§–∏–Ω–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Ç–∞–±–ª–∏—Ü—ã —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏: {df.shape}\")\n",
    "print(f\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–±–µ–∑ target): {len([c for c in df.columns if c != 'target'])}\")\n",
    "\n",
    "# –°–≤–æ–¥–∫–∞ –ø–æ —Å–æ–∑–¥–∞–Ω–Ω—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º\n",
    "print(f\"\\nüìä –°–í–û–î–ö–ê –ü–û –°–û–ó–î–ê–ù–ù–´–ú –ü–†–ò–ó–ù–ê–ö–ê–ú:\")\n",
    "print(f\"  - –í—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: ~13 (—á–∞—Å, –¥–µ–Ω—å, —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è)\")\n",
    "print(f\"  - –ü—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é: ~8 (—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é)\")\n",
    "print(f\"  - Rolling-window –ø—Ä–∏–∑–Ω–∞–∫–∏: ~{len(TIME_WINDOWS) * 5} (–¥–ª—è –æ–∫–æ–Ω {TIME_WINDOWS})\")\n",
    "print(f\"  - –°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: ~{len([c for c in df.columns if 'zscore' in c or 'percentile' in c or 'ratio' in c or 'cv' in c])}\")\n",
    "print(f\"  - Device/OS/IP/Geo –ø—Ä–∏–∑–Ω–∞–∫–∏: –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –Ω–∞–ª–∏—á–∏—è –¥–∞–Ω–Ω—ã—Ö\")\n",
    "print(f\"  - –ü—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ–≤–µ–¥–µ–Ω–∏—è: ~10+ (—Å–∫–æ—Ä–æ—Å—Ç—å, –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã, –∞–Ω–æ–º–∞–ª–∏–∏)\")\n",
    "print(f\"\\n‚úÖ –í—Å–µ –∑–∞–¥–∞—á–∏ Feature Engineering (23-28) –≤—ã–ø–æ–ª–Ω–µ–Ω—ã!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8831290e-b5e5-4864-b4ec-0c5e3c171e75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
